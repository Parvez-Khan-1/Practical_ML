{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN is an supervised machine learning algorithm used for both regression and classification.\n",
    "- KNN assumes that similar things exists in close proximity/distance.\n",
    "- KNN has no model other than storing the entire dataset, so there is no learning required.\n",
    "- KNN is oftern referred as Lazy learning algorithm as no learning of the model is required and all of the work happens at the time a prediction is requested.\n",
    "- Another good application of KNN is it can be used for imputing missing values, both continous and categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to calculate distance between two points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.mathsisfun.com/algebra/distance-2-points.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Distance Calculation Methods:\n",
    "   - Euclidean distance = âˆš a2 + b2 \n",
    "   - Hamming Distance\n",
    "   - Manhattan Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How KNN Works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data\n",
    "2. Initialize K to your chosen number of neighbors\n",
    "3. For each example in the data\n",
    "    3.1 Calculate the distance between the query example and the current example from the data.\n",
    "    3.2 Add the distance and the index of the example to an ordered collection\n",
    "4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n",
    "5. Pick the first K entries from the sorted collection\n",
    "6. Get the labels of the selected K entries\n",
    "7. If regression, return the <b>mean</b> of the K labels\n",
    "8. If classification, return the <b>mode</b> of the K labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def knn(data, query, k, distance_fn, choice_fn):\n",
    "    neighbor_distances_and_indices = []\n",
    "    \n",
    "    # 3. For each example in the data\n",
    "    for index, example in enumerate(data):\n",
    "        # 3.1 Calculate the distance between the query example and the current\n",
    "        # example from the data.\n",
    "        distance = distance_fn(example[:-1], query)\n",
    "        \n",
    "        # 3.2 Add the distance and the index of the example to an ordered collection\n",
    "        neighbor_distances_and_indices.append((distance, index))\n",
    "    \n",
    "    # 4. Sort the ordered collection of distances and indices from\n",
    "    # smallest to largest (in ascending order) by the distances\n",
    "    sorted_neighbor_distances_and_indices = sorted(neighbor_distances_and_indices)\n",
    "    \n",
    "    # 5. Pick the first K entries from the sorted collection\n",
    "    k_nearest_distances_and_indices = sorted_neighbor_distances_and_indices[:k]\n",
    "    \n",
    "    # 6. Get the labels of the selected K entries\n",
    "    k_nearest_labels = [data[i][-1] for distance, i in k_nearest_distances_and_indices]\n",
    "\n",
    "    # 7. If regression (choice_fn = mean), return the average of the K labels\n",
    "    # 8. If classification (choice_fn = mode), return the mode of the K labels\n",
    "    return k_nearest_distances_and_indices , choice_fn(k_nearest_labels)\n",
    "\n",
    "def mean(labels):\n",
    "    return sum(labels) / len(labels)\n",
    "\n",
    "def mode(labels):\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    sum_squared_distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        sum_squared_distance += math.pow(point1[i] - point2[i], 2)\n",
    "    return math.sqrt(sum_squared_distance)\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    # Regression Data\n",
    "    # \n",
    "    # Column 0: height (inches)\n",
    "    # Column 1: weight (pounds)\n",
    "    '''\n",
    "    reg_data = [\n",
    "       [65.75, 112.99],\n",
    "       [71.52, 136.49],\n",
    "       [69.40, 153.03],\n",
    "       [68.22, 142.34],\n",
    "       [67.79, 144.30],\n",
    "       [68.70, 123.30],\n",
    "       [69.80, 141.49],\n",
    "       [70.01, 136.46],\n",
    "       [67.90, 112.37],\n",
    "       [66.49, 127.45],\n",
    "    ]\n",
    "    \n",
    "    # Question:\n",
    "    # Given the data we have, what's the best-guess at someone's weight if they are 60 inches tall?\n",
    "    reg_query = [60]\n",
    "    reg_k_nearest_neighbors, reg_prediction = knn(\n",
    "        reg_data, reg_query, k=3, distance_fn=euclidean_distance, choice_fn=mean\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
    "- https://machinelearningmastery.com/k-nearest-neighbors-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
